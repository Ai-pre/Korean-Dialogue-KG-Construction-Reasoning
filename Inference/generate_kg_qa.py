import json
import random
import time
import re
from openai import OpenAI

# =========================
# OpenAI client
# =========================
client = OpenAI(
    api_key="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"
)

# =========================
# Relation definition
# =========================
RELATION_DEFINITION = {
    "xIntent": "í–‰ìœ„ìê°€ ì´ ë°œí™”ë‚˜ í–‰ë™ì„ í•˜ê²Œ ë§Œë“  ëª©ì  ë˜ëŠ” ì´ìœ ",
    "xEffect": "ì‚¬ê±´ ì´í›„ í–‰ìœ„ì ìì‹ ì—ê²Œ ì§ì ‘ì ìœ¼ë¡œ ë°œìƒí•œ ê²°ê³¼",
    "xReact": "ì‚¬ê±´ ì´í›„ í–‰ìœ„ìê°€ ëŠë‚„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê°ì •",
    "oReact": "ì´ ì‚¬ê±´ì„ ë“¤ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ëŠë‚„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê°ì •",
    "oWant": "ì´ ì‚¬ê±´ ì´í›„ ì£¼ë³€ ì‚¬ëŒë“¤ì´ ì›í•˜ê²Œ ë˜ëŠ” í–‰ë™ ë˜ëŠ” ìƒíƒœ",
}

RELATION_QUESTION = {
    "xIntent": "ì™œ í–‰ìœ„ìëŠ” ì´ëŸ° ë§ì„ í•˜ê±°ë‚˜ í–‰ë™ì„ í–ˆì„ê¹Œ?",
    "xEffect": "ì´ ì‚¬ê±´ ì´í›„, í–‰ìœ„ìì—ê²Œ ì–´ë–¤ ë³€í™”ê°€ ì¼ì–´ë‚¬ì„ê¹Œ?",
    "xReact": "ì´ ì‚¬ê±´ ì´í›„, í–‰ìœ„ìëŠ” ì–´ë–¤ ê°ì •ì„ ëŠê¼ˆì„ê¹Œ?",
    "oReact": "ì´ ì‚¬ê±´ì„ ë“¤ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì€ ì–´ë–¤ ê°ì •ì„ ëŠê¼ˆì„ê¹Œ?",
    "oWant": "ì´ ì‚¬ê±´ ì´í›„, ì£¼ë³€ ì‚¬ëŒë“¤ì€ ë¬´ì—‡ì„ ì›í•˜ê²Œ ë˜ì—ˆì„ê¹Œ?",
}

# =========================
# Prompt builder (FULL VERSION ìœ ì§€)
# =========================
def build_prompt(head, relation):
    return f"""
ë‹¹ì‹ ì€ ì‚¬ê±´ ê¸°ë°˜ ìƒì‹ ì¸ê³¼ ì¶”ë¡  ëª¨ë¸ì…ë‹ˆë‹¤.

[ì‚¬ê±´]
{head}

[ê´€ê³„ ì •ì˜]
{relation}: {RELATION_DEFINITION[relation]}

[ì§ˆë¬¸]
{RELATION_QUESTION[relation]}

[ì¶œë ¥ ê·œì¹™]
- ë°˜ë“œì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•  ê²ƒ
- ì‚¬ê±´ì„ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ê±°ë‚˜ ë°”ê¿” ë§í•˜ì§€ ë§ ê²ƒ
- {relation}ì˜ ì •ì˜ë¥¼ ë²—ì–´ë‚˜ëŠ” ë‚´ìš©ì€ ê¸ˆì§€
- ì¦‰ê°ì ì´ê³  ì§ì ‘ì ì¸ ì¸ê³¼/ê°ì •ë§Œ í—ˆìš©
- ëª¨í˜¸í•œ í‘œí˜„(â€œì–´ë–¤â€, â€œë¬´ì–¸ê°€â€) ì‚¬ìš© ê¸ˆì§€
- ë‹¨ì¼ ê²°ê³¼ / ë‹¨ì¼ ê°ì •ë§Œ í—ˆìš©
"""

# =========================
# Generic intent / want filter
# =========================
ABSTRACT_NOUNS = [
    "ì‚¬íšŒ", "ì •ì˜", "ë„ë•", "ìœ¤ë¦¬", "ê°€ì¹˜", "ì•ˆì •", "ì§ˆì„œ",
    "ì¤‘ìš”ì„±", "í•„ìˆ˜", "í•„ìš”ì„±", "ì±…ì„", "ì˜ë¬´", "ì›ì¹™"
]

NORMATIVE_PHRASES = [
    "ì¤‘ìš”í•˜ë‹¤ê³ ", "í•„ìˆ˜ì ", "ë°”ëŒì§", "ì˜³ë‹¤ê³ ",
    "í•´ì•¼ í•œë‹¤", "ë¯¿ì—ˆê¸° ë•Œë¬¸ì—", "ìƒê°í–ˆê¸° ë•Œë¬¸ì—"
]

CAMPAIGN_EXPRESSIONS = [
    "ëª¨ë‘", "ì‚¬ëŒë“¤ì€", "ìš°ë¦¬ ì‚¬íšŒ",
    "ëˆ„êµ¬ë‚˜", "ì¼ë°˜ì ìœ¼ë¡œ", "ì‚¬íšŒì ìœ¼ë¡œ"
]

PURPOSE_WEAK_ENDINGS = [
    "ì•Œë¦¬ê¸° ìœ„í•´", "ì „ë‹¬í•˜ê¸° ìœ„í•´", "ê³µìœ í•˜ê¸° ìœ„í•´"
]

def is_generic_intent_or_want(answer: str) -> bool:
    if sum(1 for w in ABSTRACT_NOUNS if w in answer) >= 2:
        return True
    if any(p in answer for p in NORMATIVE_PHRASES):
        return True
    if any(p in answer for p in CAMPAIGN_EXPRESSIONS):
        return True
    if any(answer.strip().endswith(p) for p in PURPOSE_WEAK_ENDINGS):
        return True
    if not re.search(r"(í–‰ìœ„ì|ì£¼ë³€ ì‚¬ëŒ|ìƒëŒ€ë°©|ë‹¤ë¥¸ ì‚¬ëŒ)", answer):
        return True
    return False

# =========================
# Extra strict ATOMIC filters (A-mode)
# =========================
def violates_xeffect_subject(answer: str) -> bool:
    return any(w in answer for w in ["ìƒëŒ€ë°©", "ë‹¤ë¥¸ ì‚¬ëŒ", "ì£¼ë³€ ì‚¬ëŒ"])

def has_multiple_effects(answer: str) -> bool:
    return any(w in answer for w in ["ê·¸ë¦¬ê³ ", "ê³  ", "ë©° ", "ë°"])

def is_redundant_react(head: str, answer: str) -> bool:
    redundant_keywords = ["ë°°ê³ í”„", "ì¡¸ë¦¬", "ì·¨í•˜", "ì•„í”„"]
    return any(k in head and k in answer for k in redundant_keywords)

COGNITIVE_EMOTION_WORDS = [
    "ì‹¬ê°ì„±", "ë¬¸ì œì˜ì‹", "ìœ„í—˜ì„±", "ê²½ê°ì‹¬",
    "ì¸ì‹", "ê¹¨ë‹¬", "ì´í•´"
]

def is_over_reasoned_oreact(answer: str) -> bool:
    return any(w in answer for w in COGNITIVE_EMOTION_WORDS)

def has_multiple_emotions(answer: str) -> bool:
    return any(w in answer for w in ["ê³¼", "ì™€", "ë°"])

# =========================
# Quality filter (FINALâ€“A)
# =========================
def is_low_quality(head, answer, relation):
    head_tokens = set(re.findall(r"\w+", head))
    ans_tokens = set(re.findall(r"\w+", answer))
    if len(head_tokens & ans_tokens) / max(len(head_tokens), 1) > 0.6:
        return True

    if any(b in answer for b in ["ì•Œê²Œ ë˜ì—ˆë‹¤", "ë§í–ˆë‹¤", "ì–¸ê¸‰í–ˆë‹¤", "ì†Œê°œí–ˆë‹¤"]):
        return True

    if relation == "xEffect" and any(w in answer for w in ["ëŠê¼ˆ", "ê°ì •"]):
        return True

    if relation in ["xReact", "oReact"] and any(w in answer for w in ["ì›í•˜ê²Œ", "ê²°ì‹¬", "í–‰ë™"]):
        return True

    if relation in ["xIntent", "oWant"] and is_generic_intent_or_want(answer):
        return True

    if relation == "xEffect":
        if violates_xeffect_subject(answer) or has_multiple_effects(answer):
            return True

    if relation == "xReact":
        if is_redundant_react(head, answer) or has_multiple_emotions(answer):
            return True

    if relation == "oReact" and is_over_reasoned_oreact(answer):
        return True

    return False

# =========================
# GPT call
# =========================
def generate_answer(head, relation):
    prompt = build_prompt(head, relation)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    return response.choices[0].message.content.strip()

# =========================
# Main (dialog_triples.json ëŒ€ì‘)
# =========================
def main():
    INPUT_PATH = "/home/jaesang/kg_project/output/dialog_triples.json"
    OUTPUT_PATH = "/home/jaesang/kg_project/output/kg_qa_samples_FINAL.jsonl"

    with open(INPUT_PATH, "r", encoding="utf-8") as f:
        dialog_files = json.load(f)

    # ğŸ”¥ dialog_triples êµ¬ì¡° flatten
    triples = []
    for doc in dialog_files:
        for tri in doc["triples"]:
            if tri["relation"] in RELATION_DEFINITION:
                triples.append(tri)

    random.shuffle(triples)

    saved = 0
    with open(OUTPUT_PATH, "w", encoding="utf-8") as out_f:
        for idx, tri in enumerate(triples):
            head = tri["head"]
            relation = tri["relation"]
            tail = tri["tail"]

            try:
                answer = generate_answer(head, relation)

                if is_low_quality(head, answer, relation):
                    print(f"[SKIP] {relation} :: {answer}", flush=True)
                    continue

                sample = {
                    "messages": [
                        {
                            "role": "user",
                            "content": f"{head}\n\n{RELATION_QUESTION[relation]}"
                        },
                        {
                            "role": "assistant",
                            "content": answer
                        }
                    ],
                    "source_triple": {
                        "head": head,
                        "relation": relation,
                        "tail": tail
                    }
                }

                out_f.write(json.dumps(sample, ensure_ascii=False) + "\n")
                out_f.flush()

                saved += 1
                print(f"[OK] {saved} saved", flush=True)
                time.sleep(0.4)

            except Exception as e:
                print(f"[ERROR] {idx}: {e}", flush=True)

    print(f"\n=== DONE: {saved} ATOMIC-strict QA samples generated ===", flush=True)

if __name__ == "__main__":
    main()
